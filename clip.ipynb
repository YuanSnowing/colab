{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuanSnowing/colab/blob/main/clip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YadOCCCyXT0y"
      },
      "outputs": [],
      "source": [
        "!pip install openai-clip torchvision torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def compute_clip_similarity(images, text):\n",
        "    # 加载CLIP模型和预训练权重\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model, preprocess = clip.load(\"ViT-B/32\", device)\n",
        "\n",
        "    # 处理文本和图像\n",
        "    text_input = clip.tokenize([text]).to(device)\n",
        "    image_features = []\n",
        "\n",
        "    for image_path in images:\n",
        "        # 加载和处理图像\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        image_input = preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "        # 获取图像特征\n",
        "        with torch.no_grad():\n",
        "            image_feature = model.encode_image(image_input)\n",
        "        image_features.append(image_feature)\n",
        "\n",
        "    # 获取文本特征\n",
        "    with torch.no_grad():\n",
        "        text_feature = model.encode_text(text_input)\n",
        "\n",
        "    # 计算图像和文本之间的相似度\n",
        "    similarities = []\n",
        "    for image_feature in image_features:\n",
        "        # 计算余弦相似度\n",
        "        similarity = torch.cosine_similarity(image_feature, text_feature)\n",
        "        similarities.append(similarity.item())\n",
        "\n",
        "    # 计算平均相似度\n",
        "    avg_similarity = np.mean(similarities)\n",
        "    return avg_similarity\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1jMI6tjN69il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 输入：三张图像路径和一个文本\n",
        "image_paths = [\"/content/1.png\"]\n",
        "text_input = \"A boat on the water\"\n",
        "\n",
        "# 计算相似度\n",
        "average_similarity = compute_clip_similarity(image_paths, text_input)\n",
        "print(f\"Average CLIP Similarity: {average_similarity}\")"
      ],
      "metadata": {
        "id": "-YJ1rTBT7DBr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}